{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24a5f4e6",
   "metadata": {},
   "source": [
    "# Support Vector Machine Classification\n",
    "\n",
    "## Apa Yang Akan Dilakukan Pada Notebook Ini?\n",
    "\n",
    "    1. Penjelasan SVM Algorithm, komponen-komponen terkait, beserta mathematics formula pada SVM\n",
    "    2. Pengerjaan Titanic Dataset Menggunakan model Support Vector Classifier\n",
    "\n",
    "## Apa Sajakah Kasus Penggunaan SVM?\n",
    "\n",
    "<blockquote> Classification (Support Vector Classifier) </blockquote>\n",
    "\n",
    "<blockquote> Regression (time series prediction, etc) </blockquote>\n",
    "\n",
    "## Bagaimana SVM dibandingkan dengan algoritma ML lainnya?\n",
    "\n",
    "![alt text](https://image.slidesharecdn.com/mscpresentation-140722065852-phpapp01/95/msc-presentation-bioinformatics-7-638.jpg?cb=1406012610 \"Compare Between SVM and NN\")\n",
    "\n",
    "- Sebagai aturan praktis, SVM sangat bagus untuk kumpulan data yang relatif kecil dengan outlier yang lebih sedikit.\n",
    "- Algoritma lain (Random forests, deep neural networks, dll.) memerlukan lebih banyak data tetapi hampir selalu menghasilkan model yang sangat kuat.\n",
    "\n",
    "    1. SVM vs. Neural Networks:\n",
    "    - Perbedaan: SVM menggunakan pendekatan geometris dalam menemukan hyperplane terbaik, sementara Neural Networks\n",
    "    menggunakan arsitektur jaringan yang kompleks untuk menemukan pola yang rumit.\n",
    "    - Kapan memilih: Jika terdapat kebutuhan untuk interpretasi dan kecepatan komputasi yang cepat, SVM mungkin lebih\n",
    "    diinginkan. Namun, jika tugas memerlukan adaptasi terhadap pola yang sangat kompleks dan data besar, Neural Networks\n",
    "    bisa menjadi alternatif yang lebih baik.\n",
    "\n",
    "    2. SVM vs. Regresi Logistik:\n",
    "    - Perbedaan: SVM berfokus pada menemukan hyperplane terbaik yang memisahkan kelas-kelas, sementara Regresi Logistik\n",
    "    memodelkan probabilitas untuk kelas tertentu.\n",
    "    - Kapan memilih: SVM lebih cocok ketika ada kompleksitas pemisahan antar kelas yang tinggi dan ketika margin pemisahan\n",
    "    yang optimal diinginkan. Regresi Logistik sering digunakan ketika interpretasi probabilitas kelas adalah kebutuhan\n",
    "    utama.\n",
    "\n",
    "    3. SVM vs. Decision Trees (Pohon Keputusan):\n",
    "    - Perbedaan: SVM mencari hyperplane yang memaksimalkan margin antara kelas, sementara Decision Trees membagi ruang fitur\n",
    "    menggunakan serangkaian keputusan berbasis fitur.\n",
    "    - Kapan memilih: Jika data memiliki kompleksitas tinggi dan jumlah fitur besar, SVM dapat memberikan performa yang baik.\n",
    "    Namun, jika interpretasi yang lebih mudah dan pemahaman fitur yang diperlukan, Decision Trees bisa menjadi pilihan yang\n",
    "    baik.\n",
    "\n",
    "    4. SVM vs. K-Nearest Neighbors (K-NN):\n",
    "    - Perbedaan: SVM mencari hyperplane terbaik sebagai batas keputusan, sementara K-NN menggunakan informasi tetangga\n",
    "    terdekat untuk mengklasifikasikan data.\n",
    "    - Kapan memilih: Jika data bersifat linier atau hampir linier dipisahkan, SVM mungkin memberikan hasil yang lebih baik.\n",
    "    Namun, jika tidak ada asumsi linieritas dan interpretasi jarak antar data penting, K-NN bisa menjadi alternatif yang\n",
    "    baik.\n",
    "\n",
    "    5. SVM vs. Random Forests:\n",
    "    - Perbedaan: SVM mencari hyperplane linier atau non-linier, sedangkan Random Forests adalah ensemble dari Decision Trees.\n",
    "    - Kapan memilih: Jika ada kebutuhan untuk menangani data dengan kompleksitas yang tinggi dan menghindari overfitting, SVM mungkin lebih cocok. Namun, jika interpretasi yang lebih mudah dan kemampuan untuk menangani banyak fitur serta deteksi\n",
    "    pentingnya fitur, Random Forests bisa lebih baik.\n",
    "\n",
    "\n",
    "## Apa itu Support Vector Machine?\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png \"Logo Title Text 1\")\n",
    "\n",
    "Dalam formulasi SVM dalam persamaan linear:\n",
    "\n",
    "$ f(x) = w^T x + b $\n",
    "\n",
    "di mana:\n",
    "- $ f(x) $ adalah fungsi prediksi.\n",
    "- $ w $ adalah vektor bobot (weight vector) yang bertanggung jawab untuk mengontrol orientasi hyperplane.\n",
    "- $ x $ adalah vektor fitur input.\n",
    "- $ b $ adalah bias (sering juga disebut sebagai \"intercept\" dalam konteks linier) yang menentukan posisi hyperplane dalam ruang fitur.\n",
    "\n",
    "Ini adalah `Supervised Machine Learning Algorithm` yang dapat digunakan untuk masalah `klasifikasi atau regresi`. Tapi biasanya digunakan untuk klasifikasi. Diberikan 2 atau lebih kelas data yang diberi label, ia bertindak sebagai pengklasifikasi diskriminatif. `Pengklasifikasi diskriminatif` merujuk pada kategori algoritma pembelajaran mesin yang bertujuan untuk menemukan `batas keputusan` atau hyperplane pemisah yang `membedakan` antara kelas atau kelompok yang berbeda dalam data. `Tujuan utama` dari pengklasifikasi diskriminatif adalah untuk `mengidentifikasi aturan atau fungsi yang memungkinkan pemisahan yang optimal antara kelas-kelas yang berbeda`. Secara formal SVM ditentukan oleh `hyperplane optimal` yang memisahkan semua kelas. Contoh-contoh baru yang kemudian dipetakan ke dalam ruang yang sama kemudian dapat dikategorikan berdasarkan pada sisi kesenjangan mana contoh-contoh tersebut berada.\n",
    "\n",
    "## Apa itu Support Vectors?\n",
    "\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:1400/0*ecA4Ls8kBYSM5nza.jpg \"Logo Title Text 1\")\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:720/format:webp/1*CD08yESKvYgyM7pJhCnQeQ.png \"Logo Title Text 1\")\n",
    "![alt text](https://miro.medium.com/v2/resize:fit:828/format:webp/1*ikAtK9PHxDH1xDvaXEUKTw.png \"Logo Title Text 1\")\n",
    "\n",
    "\n",
    " \n",
    "`Support Vektor` adalah titik data yang `paling dekat` dengan hyperplane, `titik dari kumpulan data` yang, jika dihilangkan, akan mengubah posisi hyperplane pemisah. hyperplane dibangun berdasarkan maksimum margin dari suport vektor itu sendiri. Beberapa kasus juga bisa menggunakan `soft margin` dengan metode misclasification. Oleh karena itu, mereka dapat dianggap sebagai elemen penting dari kumpulan data, dan `merekalah` yang membantu `kita membangun SVM`.\n",
    "\n",
    "## Apa itu Hyperplane?\n",
    "\n",
    "![alt text](http://slideplayer.com/slide/1579281/5/images/32/Hyperplanes+as+decision+surfaces.jpg \"Logo Title Text 1\")\n",
    "\n",
    "`Geometri` memberi tahu kita bahwa `hyperplane` adalah subruang yang satu dimensinya lebih kecil dari ruang sekitarnya. Misalnya, `hyperplane` dari ruang `berdimensi n` adalah himpunan bagian datar dengan dimensi `n âˆ’ 1`. Berdasarkan sifatnya, ia memisahkan ruang menjadi dua setengah ruang.\n",
    "\n",
    "## Linear vs Nonlinear classification?\n",
    "\n",
    "Terkadang data kita dapat dipisahkan `secara linier`. Artinya untuk `N kelas dengan M fitur`, kita dapat mempelajari pemetaan yang merupakan `kombinasi linier`. (seperti `$y = mx + b$`). Atau bahkan `hyperplane multidimensi` (`$y = x + z + b + q$`). `Tidak peduli berapa banyak dimensi/fitur` yang dimiliki suatu kumpulan kelas, kita dapat `merepresentasikan` pemetaan menggunakan `fungsi linier`.\n",
    "\n",
    "Namun, ketika `data tidak dapat dipisahkan secara linier` dalam ruang fitur asli, `SVM` menggunakan apa yang disebut `\"trik kernel\"` untuk mengatasi kendala ini. `Trik kernel` memungkinkan SVM untuk melakukan `transformasi nonlinear data` ke dalam `ruang dimensi yang lebih tinggi`. Ide dasarnya adalah `mengubah data ke ruang fitur yang berbeda di mana pola kelas mungkin dapat dipisahkan secara linier`.\n",
    "\n",
    "Beberapa jenis fungsi kernel yang umum digunakan dalam SVM adalah:\n",
    "\n",
    "- `Linear Kernel`: Cocok untuk pemetaan linier dan digunakan ketika data dapat dipisahkan secara linier.\n",
    "- `Polynomial Kernel`: Mampu menangani pola non-linier dengan menambahkan derajat pada pemetaan polinomial (contohnya, $x^2$, $x^3$, dst.)\n",
    "- `Gaussian RBF (Radial Basis Function) Kernel`: Efektif dalam menangani pemetaan non-linier kompleks dengan transformasi ke ruang dimensi yang tak terbatas.\n",
    "\n",
    "![alt text](https://files.codingninjas.in/article_images/linear-vs-non-linear-classification-5-1641818083.webp \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a2ae73",
   "metadata": {},
   "source": [
    "## Beberapa mathematics formula yang wajib diketahui\n",
    "\n",
    "1. Hyperplane with Maksimum Margin (Mencegah Overfit Pada Model):\n",
    "optimasi untuk menemukan hyperplane yang optimal dalam pemisahan kelas.\n",
    "\n",
    "Fungsi tujuan regularized risk dalam SVM:\n",
    "$ \\min_{w, b} \\frac{1}{2} ||w||^2 + C \\sum_{i=1}^{N} \\xi_i $\n",
    "\n",
    "Di sini:\n",
    "- $ \\frac{1}{2} ||w||^2 $ merupakan bagian dari fungsi tujuan yang bertujuan untuk meminimalkan norma Euclidean dari vektor bobot $ w $, yang mencerminkan elemen regularisasi dalam SVM.\n",
    "- $ C $ adalah parameter penalti yang mengontrol trade-off antara meminimalkan kesalahan klasifikasi dan memperbesar margin.\n",
    "- $ \\sum_{i=1}^{N} \\xi_i $ adalah penjumlahan dari variabel slack $ \\xi_i $, yang memungkinkan kesalahan klasifikasi pada titik-titik data yang mungkin tidak terpisahkan secara sempurna oleh hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bcc5ab",
   "metadata": {},
   "source": [
    "Penerapan Kernel trick in SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "879dcc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import YouTubeVideo\n",
    "# YouTubeVideo('_YPScrckx28')\n",
    "# # start in - 1:42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7c3b3e",
   "metadata": {},
   "source": [
    "# Pengerjaan Titanic Dataset Menggunakan model Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4285f530",
   "metadata": {},
   "source": [
    "<blockquote> SVM sebagai algoritma untuk memprediksi hasil kelangsungan hidup penumpang di Titanic </blockquote>\n",
    "\n",
    "---\n",
    "`Ringkasan Proyek`: Tenggelamnya RMS Titanic adalah salah satu bangkai kapal paling terkenal dalam sejarah. Pada tanggal 15 April 1912, selama pelayaran perdananya, Titanic tenggelam setelah bertabrakan dengan gunung es, menewaskan 1.502 dari 2.224 penumpang dan awak. Tragedi sensasional ini mengejutkan komunitas internasional dan menghasilkan peraturan keselamatan kapal yang lebih baik.\n",
    "\n",
    "`Permasalahan` : Salah satu alasan mengapa kapal karam menyebabkan banyak korban jiwa adalah karena tidak tersedianya sekoci yang cukup untuk penumpang dan awak kapal. Meskipun ada unsur keberuntungan dalam selamat dari tenggelamnya kapal tersebut, beberapa kelompok orang lebih mungkin untuk selamat dibandingkan kelompok lainnya, seperti wanita, anak-anak, dan kelas atas.\n",
    "\n",
    "`Hasil yang diingingkan` : Penyelesaian analisis tentang orang-orang seperti apa yang kemungkinan besar akan bertahan hidup. Secara khusus, melakukan penerapan alat pembelajaran mesin untuk memprediksi penumpang mana yang selamat dari tragedi tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fc49d",
   "metadata": {},
   "source": [
    "# Metadata Dataset\n",
    "\n",
    "| Variable | Definition                              | Key                                               |\n",
    "|:----------|:-----------------------------------------:|:----------------------------------------------------|\n",
    "| survival | Survival                                | 0 = No, 1 = Yes                                    |\n",
    "| pclass   | Ticket class                            | 1 = 1st, 2 = 2nd, 3 = 3rd                          |\n",
    "| sex      | Sex                                     |                                                    |\n",
    "| Age      | Age in years                            |                                                    |\n",
    "| sibsp    | # of siblings / spouses aboard the Titanic |                                                  |\n",
    "| parch    | # of parents / children aboard the Titanic |                                                  |\n",
    "| ticket   | Ticket number                           |                                                    |\n",
    "| fare     | Passenger fare                          |                                                    |\n",
    "| cabin    | Cabin number                            |                                                    |\n",
    "| embarked | Port of Embarkation                     | C = Cherbourg, Q = Queenstown, S = Southampton      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe159b",
   "metadata": {},
   "source": [
    "Variable Notes:\n",
    "\n",
    "- **pclass**: Variabel ini merupakan proxy atau representasi untuk status sosial ekonomi (SES) penumpang.\n",
    "    - Nilai 1st mewakili kelas atas/tinggi.\n",
    "    - Nilai 2nd mewakili kelas menengah.\n",
    "    - Nilai 3rd mewakili kelas bawah/rendah.\n",
    "\n",
    "- **age**: Variabel usia (umur) penumpang.\n",
    "    - Usia ditulis dalam bentuk pecahan jika kurang dari 1. Jika usia diestimasi, ditulis dalam format xx.5.\n",
    "\n",
    "- **sibsp**: Variabel ini menjelaskan hubungan keluarga dalam dataset:\n",
    "    - \"Sibling\" merujuk pada saudara kandung seperti saudara laki-laki, saudara perempuan, saudara tiri, atau saudara tiri perempuan.\n",
    "    - \"Spouse\" merujuk pada pasangan seperti suami atau istri (gundik dan tunangan diabaikan).\n",
    "\n",
    "- **parch**: Variabel ini juga menjelaskan hubungan keluarga dalam dataset:\n",
    "    - \"Parent\" merujuk pada orang tua seperti ibu atau ayah.\n",
    "    - \"Child\" merujuk pada anak seperti anak perempuan, anak laki-laki, anak tiri perempuan, atau anak tiri laki-laki.\n",
    "    - Beberapa anak hanya pergi bersama pengasuh, sehingga memiliki nilai parch=0.\n",
    "\n",
    "Informasi ini membantu dalam memahami dan menafsirkan variabel-variabel dalam dataset Titanic, memberikan konteks tentang atribut-atribut yang ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2955d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7526f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "265.55px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
